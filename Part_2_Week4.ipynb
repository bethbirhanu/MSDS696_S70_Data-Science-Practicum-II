{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN/arJiqw9OwwXDEfR4/G5n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bethbirhanu/MSDS696_S70_Data-Science-Practicum-II/blob/main/Part_2_Week4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__FUminNyNXa",
        "outputId": "4d5daaf0-3679-4700-c8e2-b60a7eba1b4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "id": "58IqlYXyyqu7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the cleaned 2007-2020 dataset from the CSV file\n",
        "df_2007_2020_clean = pd.read_csv('/content/drive/My Drive/df_2007_2020_clean.csv')\n",
        "\n",
        "# Load the cleaned 2021-2022 dataset from the CSV file\n",
        "df_2021_2022_clean = pd.read_csv('/content/drive/My Drive/df_2021_2022_clean.csv')"
      ],
      "metadata": {
        "id": "cGfXTNB6yhrb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Select columns with non-numeric data types\n",
        "categorical_cols = df_2007_2020_clean.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "\n",
        "for col in df_2007_2020_clean.select_dtypes(include=['int64', 'float64']).columns:\n",
        "    if len(df_2007_2020_clean[col].unique()) < 10:  # the threshold can be adjusted\n",
        "        categorical_cols = categorical_cols.append(pd.Index([col]))\n",
        "\n",
        "# Print out the categorical columns\n",
        "print(categorical_cols)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGCdrGXvzDwd",
        "outputId": "c7a56e21-b3dd-482a-f710-1cff737e093a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['SYSTEM', 'DATE', 'SEVERITY', 'ROAD_DESC', 'CONTOUR', 'CONDITION',\n",
            "       'LIGHTING', 'WEATHER', 'LIMIT1', 'RUCODE', 'MHE', 'VEHICLE_1',\n",
            "       'DRIVER_1', 'FACTOR_1', 'VEH_MOVE_1', 'SEX_1', 'CITY', 'COUNTY',\n",
            "       'REGION'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select columns with non-numeric data types\n",
        "categorical_cols1 = df_2021_2022_clean.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "for col in df_2021_2022_clean.select_dtypes(include=['int64', 'float64']).columns:\n",
        "    if len(df_2021_2022_clean[col].unique()) < 10:  # the threshold can be adjusted\n",
        "        categorical_cols1 = categorical_cols1.append(pd.Index([col]))\n",
        "\n",
        "# Print out the categorical columns\n",
        "print(categorical_cols1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djwxuW3mzLyD",
        "outputId": "925c8c63-d505-41fd-c366-ade9042708b8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['SYSTEM', 'DATE', 'SEVERITY', 'ROAD_DESC', 'CONTOUR', 'CONDITION',\n",
            "       'LIGHTING', 'WEATHER', 'LIMIT1', 'RUCODE', 'MHE', 'VEHICLE_1',\n",
            "       'DRIVER_1', 'FACTOR_1', 'VEH_MOVE_1', 'SEX_1', 'CITY', 'COUNTY',\n",
            "       'INJURY 02', 'REGION'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### using one-hot encoding 'get dummy' function changing catagorical variable to numeric"
      ],
      "metadata": {
        "id": "mR32iaZi00Hp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "# Combine datasets to ensure consistent encoding\n",
        "combined_df = pd.concat([df_2007_2020_clean, df_2021_2022_clean], sort=False)\n",
        "\n",
        "# One-hot encoding\n",
        "one_hot_cols = ['SYSTEM', 'ROAD_DESC', 'CONDITION', 'LIGHTING', 'WEATHER', 'CONTOUR', 'RUCODE', 'MHE', 'VEHICLE_1', 'DRIVER_1', 'FACTOR_1', 'VEH_MOVE_1', 'CITY', 'COUNTY']\n",
        "combined_df_encoded = pd.get_dummies(combined_df, columns=one_hot_cols)\n",
        "\n",
        "# Label encoding for any ordinal categories or high cardinality nominal categories\n",
        "label_encoder = LabelEncoder()\n",
        "label_cols = ['SEX_1', 'REGION']\n",
        "for col in label_cols:\n",
        "    combined_df_encoded[col] = label_encoder.fit_transform(combined_df_encoded[col].astype(str))\n",
        "\n",
        "# Split the combined dataset back into training and testing sets\n",
        "df_2007_2020_encoded = combined_df_encoded[:len(df_2007_2020_clean)]\n",
        "df_2021_2022_encoded = combined_df_encoded[len(df_2007_2020_clean):]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eokUg9aJ1C5L"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use pandas get_dummies for one-hot encoding\n",
        "df_2007_2020_encoded = pd.get_dummies(df_2007_2020_encoded, columns=['REGION'])\n",
        "df_2021_2022_encoded = pd.get_dummies(df_2021_2022_encoded, columns=['REGION'])\n",
        "\n",
        "# Ensure both dataframes have the same set of columns after encoding,\n",
        "missing_cols = set(df_2007_2020_encoded.columns) - set(df_2021_2022_encoded.columns)\n",
        "for c in missing_cols:\n",
        "    df_2021_2022_encoded[c] = 0\n",
        "\n",
        "missing_cols = set(df_2021_2022_encoded.columns) - set(df_2007_2020_encoded.columns)\n",
        "for c in missing_cols:\n",
        "    df_2007_2020_encoded[c] = 0\n",
        "\n",
        "# Align the order of columns in both dataframes\n",
        "df_2007_2020_encoded, df_2021_2022_encoded = df_2007_2020_encoded.align(df_2021_2022_encoded, axis=1)\n"
      ],
      "metadata": {
        "id": "nKX28WTLPV_C"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming df_2007_2020_encoded is your dataset\n",
        "X_train = df_2007_2020_encoded.drop('SEVERITY', axis=1)  # Drop the target variable to get the features\n",
        "y_train = df_2007_2020_encoded['SEVERITY']  # Target variable\n",
        "\n"
      ],
      "metadata": {
        "id": "jbKB9LaN1-mq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Gs8ukO5ZeLPc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'DATE' to datetime if it's in string format and extract year, month, and day\n",
        "if 'DATE' in X_train.columns:\n",
        "    X_train['DATE'] = pd.to_datetime(X_train['DATE'])\n",
        "    X_train['YEAR'] = X_train['DATE'].dt.year\n",
        "    X_train['MONTH'] = X_train['DATE'].dt.month\n",
        "    X_train['DAY'] = X_train['DATE'].dt.day\n",
        "    X_train = X_train.drop('DATE', axis=1)  # Drop the original 'DATE' column if no longer needed\n",
        "\n",
        "# One-hot encode categorical variables if they exist\n",
        "categorical_columns = X_train.select_dtypes(include=['object', 'category']).columns\n",
        "X_train = pd.get_dummies(X_train, columns=categorical_columns)\n",
        "\n",
        "# Now let's retry the feature selection\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "# Define the number of features you want to keep\n",
        "k = 10  # or adjust based on your preference\n",
        "\n",
        "selector = SelectKBest(score_func=f_classif, k=k)\n",
        "X_train_selected = selector.fit_transform(X_train, y_train)\n",
        "\n",
        "selected_features = X_train.columns[selector.get_support()]\n",
        "print(f\"Selected features using ANOVA F-test: {selected_features.tolist()}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "uy1rzUbHQpE1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "745265d9-63f9-4896-f9ca-7e033a7008b2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [56] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected features using ANOVA F-test: ['INJURY 00', 'INJURY 01', 'INJURY 02', 'INJURY 03', 'MHE_BICYCLE', 'MHE_OVERTURNING', 'MHE_PEDESTRIAN', 'MHE_SIDESWIPE (SAME DIRECTION)', 'MHE_UNKNOWN', 'VEHICLE_1_MOTORCYCLE']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modeling Phase"
      ],
      "metadata": {
        "id": "6VtRFtgk9LSz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest Classifier"
      ],
      "metadata": {
        "id": "wYs22A3dQnnQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 1: Prepare the Data\n",
        "I need to ensure that both the training and testing datasets contain only the features selected during the feature selection phase. I will also extract the target variable SEVERITY from both datasets."
      ],
      "metadata": {
        "id": "ztrlpxpC9TGi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Extract the selected features from both datasets\n",
        "selected_features = ['INJURY 00', 'INJURY 01', 'INJURY 02', 'INJURY 03', 'MHE_BICYCLE', 'MHE_OVERTURNING', 'MHE_PEDESTRIAN', 'MHE_SIDESWIPE (SAME DIRECTION)', 'MHE_UNKNOWN', 'VEHICLE_1_MOTORCYCLE']\n",
        "\n",
        "X_train = df_2007_2020_encoded[selected_features]\n",
        "y_train = df_2007_2020_encoded['SEVERITY']\n",
        "\n",
        "X_test = df_2021_2022_encoded[selected_features]\n",
        "y_test = df_2021_2022_encoded['SEVERITY']\n"
      ],
      "metadata": {
        "id": "9UgPxt0n9YYm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Step 2: Train the Model\n",
        "I will train a Random Forest Classifier using the training data."
      ],
      "metadata": {
        "id": "vWNeQ6de9dYz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize the Random Forest model\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "rf_classifier.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "8JZp4iCt9e53",
        "outputId": "4c6b90e3-feee-461c-dce2-6a93fe1b51cf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Step 3: Evaluate the Model\n",
        "After training the model, I will evaluate its performance on the testing data to see how well it generalizes to new, unseen data."
      ],
      "metadata": {
        "id": "fRwHtNeA9u7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Predict on the testing set\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Accuracy Score:\")\n",
        "print(accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVcHuon_90Jp",
        "outputId": "504aa500-2291-443b-9647-74b88ca6326b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         FAT       0.66      0.32      0.43       575\n",
            "         INJ       0.99      1.00      1.00     36169\n",
            "         PDO       1.00      1.00      1.00    103275\n",
            "\n",
            "    accuracy                           1.00    140019\n",
            "   macro avg       0.88      0.77      0.81    140019\n",
            "weighted avg       1.00      1.00      1.00    140019\n",
            "\n",
            "Accuracy Score:\n",
            "0.9965219005992044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The model's performance metrics indicate a high overall accuracy score of approximately 99.65%. However, when we look closer at the precision, recall, and f1-score for each class, there's a noticeable difference:\n",
        "\n",
        "FAT (Fatalities): This class has much lower precision and recall compared to the other classes, indicating the model struggles to correctly predict fatal accidents.\n",
        "INJ (Injuries) and PDO (Property Damage Only): The model performs exceptionally well in predicting these classes, as indicated by the near-perfect scores."
      ],
      "metadata": {
        "id": "VXutV3ly-cYM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####1. Addressing Class Imbalance\n",
        "Class imbalance can significantly affect model performance, particularly for minority classes. I can use techniques like SMOTE (Synthetic Minority Over-sampling Technique) to balance the dataset."
      ],
      "metadata": {
        "id": "TWcfj4Lz-iZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Initialize SMOTE\n",
        "smote = SMOTE()\n",
        "\n",
        "# Resample the training data\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Check the balance\n",
        "print(y_train_resampled.value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-u4FmuKC-oPi",
        "outputId": "d83ab799-72fe-4989-df26-3957dce08155"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SEVERITY\n",
            "PDO    768981\n",
            "INJ    768981\n",
            "FAT    768981\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JO-ca0Ss-oEI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It looks like I've successfully balanced the classes using an oversampling technique such as SMOTE, resulting in an equal number of instances for the PDO, INJ, and FAT categories in my training data. This is a significant step in addressing class imbalance and should help improve the model's performance, especially for the minority classes."
      ],
      "metadata": {
        "id": "-GGOCnuk_go3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####2. Hyperparameter Tuning\n",
        "I can use grid search or random search to find the optimal hyperparameters for the Random Forest model."
      ],
      "metadata": {
        "id": "R5t8xT9tBc0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Define the parameter distributions\n",
        "param_distributions = {\n",
        "    'n_estimators': [100, 150, 200, 250, 300],\n",
        "    'max_depth': [10, 15, 20, 25, None],\n",
        "    'min_samples_split': [2, 4, 6, 8],\n",
        "    'min_samples_leaf': [1, 2, 3, 4]\n",
        "}\n",
        "\n",
        "# Initialize the randomized search\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=RandomForestClassifier(random_state=42),\n",
        "    param_distributions=param_distributions,\n",
        "    n_iter=3,\n",
        "    cv=3,\n",
        "    random_state=42,\n",
        "    scoring='f1_macro',\n",
        "    n_jobs=-1   # Use all available cores to speed up the process\n",
        ")\n",
        "\n",
        "# Fit the randomized search to the resampled data\n",
        "random_search.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Get the best estimator and parameters\n",
        "best_rf = random_search.best_estimator_\n",
        "print(\"Best parameters found:\", random_search.best_params_)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epD0puBoBZQQ",
        "outputId": "e9eb0c0d-dee0-4b1c-f773-c59fb19cbe21"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters found: {'n_estimators': 100, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_depth': 25}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Model Re-evaluation\n",
        "After applying the above strategies, we should re-evaluate the model performance on the testing set"
      ],
      "metadata": {
        "id": "oguRuZ8-DPTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the testing set using the best model from hyperparameter tuning\n",
        "y_pred = best_rf.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Revised Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fv31HahpDQ_u",
        "outputId": "2f524c8f-cd53-4c2d-d6e2-645c8d563937"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Revised Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         FAT       0.08      0.73      0.14       575\n",
            "         INJ       1.00      0.93      0.96     36169\n",
            "         PDO       1.00      0.98      0.99    103275\n",
            "\n",
            "    accuracy                           0.96    140019\n",
            "   macro avg       0.69      0.88      0.70    140019\n",
            "weighted avg       1.00      0.96      0.98    140019\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Logistic Regression"
      ],
      "metadata": {
        "id": "wU-AGd3WQ2ah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Initialize the model\n",
        "log_reg = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Fit the model\n",
        "log_reg.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_log_reg = log_reg.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Logistic Regression Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_log_reg))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf2Vf33tQ4gH",
        "outputId": "fa47a24e-138b-41ba-de0f-f1c65e3144ab"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         FAT       0.05      0.73      0.09       575\n",
            "         INJ       1.00      0.83      0.91     36169\n",
            "         PDO       1.00      0.98      0.99    103275\n",
            "\n",
            "    accuracy                           0.94    140019\n",
            "   macro avg       0.68      0.85      0.66    140019\n",
            "weighted avg       0.99      0.94      0.96    140019\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####2. Support Vector Machine (SVM)\n",
        "Effective in high-dimensional spaces and best suited for binary classification tasks."
      ],
      "metadata": {
        "id": "qEIdkRmjSrMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Initialize the model (using the linear kernel for faster computation)\n",
        "svm = SVC(kernel='linear')\n",
        "\n",
        "# Fit the model\n",
        "svm.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_svm = svm.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"SVM Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_svm))\n"
      ],
      "metadata": {
        "id": "LX3P2lBJQ6jV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_c2KqMoaSwyq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}